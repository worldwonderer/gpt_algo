<!DOCTYPE html>
<html lang="zh">
<head>
    <title>网络爬虫</title>
    <link rel="shortcut icon" href="/static/favicon.ico">
    <link href="/static/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/static/css/detail.css">
    <link rel="stylesheet" href="/static/css/github.css">
    <style>
        body {
            height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container-fluid {
            flex-grow: 1;
            display: flex;
            flex-direction: column;
        }
        main {
            flex-grow: 1;
        }
        .code-pre {
             white-space: pre-wrap;
             word-wrap: break-word;
        }
    </style>
</head>
<body>
    <div class="container-fluid mt-3">
        <header class="d-flex flex-column flex-md-row justify-content-md-between align-items-md-center mb-3">
            <a href="/problems" class="btn btn-secondary mb-2 mb-md-0">返回题目列表</a>
            <div class="text-md-end">
                <strong class="me-md-3 d-block d-md-inline mb-2 mb-md-0">网络爬虫</strong>
                标签:
                
                    <a href="/problems?tag=depth-first-search" class="badge bg-secondary tag-link">深度优先搜索</a>
                
                    <a href="/problems?tag=breadth-first-search" class="badge bg-secondary tag-link">广度优先搜索</a>
                
                    <a href="/problems?tag=string" class="badge bg-secondary tag-link">字符串</a>
                
                    <a href="/problems?tag=interactive" class="badge bg-secondary tag-link">交互</a>
                
                &nbsp;&nbsp;
                难度: <span class="badge bg-secondary">Medium</span>
            </div>
        </header>

        <main>
            <section class="mb-4">
                <h2>Submission</h2>
                <div class="code-block">
                    <pre class="bg-light p-2 code-pre"><code class="language-python"># &#34;&#34;&#34;
# This is HtmlParser&#39;s API interface.
# You should not implement it, or speculate about its implementation
# &#34;&#34;&#34;
#class HtmlParser(object):
#    def getUrls(self, url):
#        &#34;&#34;&#34;
#        :type url: str
#        :rtype List[str]
#        &#34;&#34;&#34;
import queue

Queue = queue.Queue

def get_domain_name(url):
    # url = url[len(&#39;http://&#39;):]
    # hostname = url.split(&#39;/&#39;)[0]
    # return f&#39;http://{hostname}&#39;
    return url.split(&#39;/&#39;)[2]


class Solution:
    def crawl(self, startUrl: str, htmlParser: &#39;HtmlParser&#39;) -&gt; List[str]:
        q = Queue()
        q.put(startUrl)

        seen = set()
        seen.add(startUrl)

        #res = [startUrl]

        target_domain_name = get_domain_name(startUrl)
        while(not q.empty()):
            url = q.get()

            candidate_urls = htmlParser.getUrls(url)
            for c in candidate_urls:
                if c not in seen and target_domain_name == get_domain_name(c):
                    q.put(c)
                    seen.add(c)
                    #res.append(c)
        return list(seen)</code></pre>
                    <button class="btn btn-sm btn-secondary copy-btn" onclick="copyCode(this)">复制代码</button>
                    <p class="mt-2 mb-0">运行时间: 172 ms</p>
                    <p class="mb-0">内存: 0.0 MB</p>
                </div>
            </section>

            
                <section>
                    <h2>Explain</h2>
                    <div>
                        <p>本题解采用广度优先搜索（BFS）策略来遍历所有与起始URL具有相同域名的网页。首先，定义一个队列来存储待访问的URL，并将起始URL加入队列和已访问集合。然后，从队列中逐个取出URL，利用HtmlParser的getUrls方法获取该URL页面上的所有链接。对于每个链接，如果它未被访问过且域名与起始URL相同，就将其加入队列和已访问集合。最终，返回已访问集合中的所有URL，即为所有可达的同域名URL。</p>
                        <p>时间复杂度: O(N*M)</p>
                        <p>空间复杂度: O(N)</p>
                        
                             <pre class="bg-light p-2 code-pre"><code class="language-python"># 解析HtmlParser API的接口定义
# class HtmlParser(object):
#     def getUrls(self, url):
#         \&#34;\&#34;\&#34;
#         :type url: str
#         :rtype List[str]
#         \&#34;\&#34;\&#34;
import queue

Queue = queue.Queue

def get_domain_name(url):
    # 提取URL的域名部分
    return url.split(&#39;/&#39;)[2]


class Solution:
    def crawl(self, startUrl: str, htmlParser: &#39;HtmlParser&#39;) -&gt; List[str]:
        q = Queue()
        q.put(startUrl)

        seen = set()
        seen.add(startUrl)

        target_domain_name = get_domain_name(startUrl)
        while(not q.empty()):
            url = q.get()

            candidate_urls = htmlParser.getUrls(url)
            for c in candidate_urls:
                if c not in seen and target_domain_name == get_domain_name(c):
                    q.put(c)
                    seen.add(c)
        return list(seen)
</code></pre>
                        
                    </div>
                </section>
            
        </main>
    </div>
    <script src="/static/js/jquery.min.js"></script>
    <script src="/static/js/bootstrap.bundle.min.js"></script>
    <script src="/static/js/highlight.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const copyButtons = document.querySelectorAll('.copy-btn');
            copyButtons.forEach(btn => {
                btn.addEventListener('click', function() {
                    copyCode(this);
                });
            });
            hljs.highlightAll();
        });

        function copyCode(button) {
            const codeBlock = button.previousElementSibling;
            const code = codeBlock.textContent;
            navigator.clipboard.writeText(code).then(function() {
                button.textContent = '已复制';
                setTimeout(function() {
                    button.textContent = '复制代码';
                }, 2000);
            }, function(err) {
                console.error('无法复制代码: ', err);
            });
        }
    </script>
</body>
</html>